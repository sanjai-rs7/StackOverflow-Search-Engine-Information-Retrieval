{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cee91fe1-958f-4272-91e0-c40ffcba4711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4508ed9d-00ef-402e-9701-bc033fae302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_file = r\"R:\\Study\\5th Sem\\Information Retrieval\\IR PROJECT\\Questions_sample.csv\"\n",
    "answers_file = r\"R:\\Study\\5th Sem\\Information Retrieval\\IR PROJECT\\Answers_sample.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7eb24785-4fcf-4981-a41b-4d45dc3efbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of stop words\n",
    "stop_words = set([\n",
    "    'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and',\n",
    "    'any', 'are', 'aren\\'t', 'as', 'at', 'be', 'because', 'been', 'before', 'being',\n",
    "    'below', 'between', 'both', 'but', 'by', 'can', 'could', 'couldn\\'t', 'did',\n",
    "    'didn\\'t', 'do', 'does', 'doesn\\'t', 'doing', 'don\\'t', 'down', 'during', 'each',\n",
    "    'few', 'for', 'from', 'further', 'had', 'hadn\\'t', 'has', 'hasn\\'t', 'have',\n",
    "    'haven\\'t', 'having', 'he', 'he\\'s', 'her', 'here', 'here\\'s', 'hers', 'herself',\n",
    "    'him', 'himself', 'his', 'how', 'i', 'i\\'m', 'if', 'in', 'into', 'is', 'isn\\'t',\n",
    "    'it', 'it\\'s', 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'might', 'mightn\\'t',\n",
    "    'more', 'most', 'must', 'mustn\\'t', 'my', 'myself', 'needn\\'t', 'no', 'nor',\n",
    "    'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our',\n",
    "    'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan\\'t', 'she',\n",
    "    'she\\'s', 'should', 'should\\'ve', 'so', 'some', 'such', 't', 'than', 'that',\n",
    "    'that\\'s', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there',\n",
    "    'there\\'s', 'these', 'they', 'they\\'re', 'this', 'those', 'through', 'to', 'too',\n",
    "    'under', 'until', 'up', 've', 'very', 'was', 'wasn\\'t', 'we', 'we\\'re', 'were',\n",
    "    'weren\\'t', 'what', 'what\\'s', 'when', 'where', 'which', 'while', 'who', 'who\\'s',\n",
    "    'whom', 'why', 'will', 'with', 'won\\'t', 'would', 'wouldn\\'t', 'you', 'you\\'re',\n",
    "    'your', 'yours', 'yourself', 'yourselves'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32a2a685-683e-4061-a688-c63fa2dbf100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "# Load Universal Sentence Encoder model\n",
    "use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da28bf18-481b-4d44-af1d-4d7736aaaa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = {} \n",
    "tfidf_documents = {} \n",
    "question_titles = {}\n",
    "use_embeddings = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "789a4423-313a-408e-b64f-52edc55661b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'R:\\Study\\5th Sem\\Information Retrieval\\IR PROJECT\\Saved Files\\HYBRID\\idf.pkl', 'rb') as f:\n",
    "    idf = pickle.load(f)\n",
    "with open(r'R:\\Study\\5th Sem\\Information Retrieval\\IR PROJECT\\Saved Files\\HYBRID\\tfidf_documents.pkl', 'rb') as f:\n",
    "    tfidf_documents = pickle.load(f)\n",
    "with open(r'R:\\Study\\5th Sem\\Information Retrieval\\IR PROJECT\\Saved Files\\HYBRID\\question_titles.pkl', 'rb') as f:\n",
    "    question_titles = pickle.load(f)\n",
    "with open(r'R:\\Study\\5th Sem\\Information Retrieval\\IR PROJECT\\Saved Files\\HYBRID\\use_embeddings.pkl', 'rb') as f:\n",
    "    use_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc7a143b-8c4c-4e1b-b4f4-88d2957ed157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores(similarity_dict):\n",
    "    if not similarity_dict:\n",
    "        return {}\n",
    "    \n",
    "    max_score = max(similarity_dict.values())\n",
    "    min_score = min(similarity_dict.values())\n",
    "\n",
    "    if max_score == min_score:\n",
    "        return {key: 1.0 for key in similarity_dict}\n",
    "\n",
    "    normalized_dict = {\n",
    "        key: (value - min_score) / (max_score - min_score)\n",
    "        for key, value in similarity_dict.items()\n",
    "    }\n",
    "    return normalized_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "abc5b9c9-709e-4cfd-bba2-7817d48c7aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_use(query_embed, candidate_embed):\n",
    "    dot_product_embed = np.dot(query_embed, candidate_embed)\n",
    "    norm_query_embed = np.linalg.norm(query_embed)\n",
    "    norm_candidate_embed = np.linalg.norm(candidate_embed)\n",
    "\n",
    "    if norm_query_embed == 0 or norm_candidate_embed == 0:\n",
    "        return 0 \n",
    "\n",
    "    return dot_product_embed / (norm_query_embed * norm_candidate_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20beade8-08ba-4aa1-95aa-5a46fc7d8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(tf_query, tf_candidate, use_query_embed, use_candidate_embed):\n",
    "    dot_product = 0\n",
    "    norm_query = 0\n",
    "    norm_candidate = 0\n",
    "\n",
    "    for word in tf_query:\n",
    "        if word in tf_candidate:\n",
    "            dot_product += tf_query[word] * tf_candidate[word]\n",
    "\n",
    "    # Calculate norms for TF-IDF vectors\n",
    "    for value in tf_query.values():\n",
    "        norm_query += value * value\n",
    "    for value in tf_candidate.values():\n",
    "        norm_candidate += value * value\n",
    "\n",
    "    # Cosine similarity for USE embeddings\n",
    "    dot_product_embed = np.dot(use_query_embed, use_candidate_embed)\n",
    "    norm_query_embed = np.linalg.norm(use_query_embed) # l2 norm(including sqrt bruh)\n",
    "    norm_candidate_embed = np.linalg.norm(use_candidate_embed)\n",
    "\n",
    "    # Final combined cosine similarity: TF-IDF similarity + USE similarity\n",
    "    if norm_query == 0 or norm_candidate == 0:\n",
    "        return 0  \n",
    "        \n",
    "    tfidf_similarity = dot_product / (norm_query**0.5 * norm_candidate**0.5)\n",
    "    use_similarity = dot_product_embed / (norm_query_embed * norm_candidate_embed)\n",
    "\n",
    "    # Return the average similarity (adjust the weight as needed)\n",
    "    return 0.5 * tfidf_similarity + 0.5 * use_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aab40260-8bab-4e55-b183-2a28137eea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_tfidf(questions_file):\n",
    "    global idf, tfidf_documents, question_titles, use_embeddings\n",
    "    term_frequencies = defaultdict(lambda: defaultdict(int))  # Term frequency per document\n",
    "    df = defaultdict(int)  # Document frequency\n",
    "    N = 0  # Total number of documents\n",
    "\n",
    "    with open(questions_file, 'r', encoding='latin-1') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader) \n",
    "        for row in reader:\n",
    "            question_id = row[0]\n",
    "            title = row[5]\n",
    "            if title:  \n",
    "                title = title.lower()  \n",
    "                words = title.split()  \n",
    "                N += 1\n",
    "                question_titles[question_id] = title\n",
    "                unique_words_in_doc = set()\n",
    "\n",
    "                for word in words:\n",
    "                    if word not in stop_words:\n",
    "                        term_frequencies[question_id][word] += 1\n",
    "                        unique_words_in_doc.add(word)\n",
    "\n",
    "        \n",
    "                for word in unique_words_in_doc:\n",
    "                    df[word] += 1\n",
    "\n",
    "    idf = {word: math.log(N / (1 + freq)) for word, freq in df.items()}  # Add 1 to avoid division by zero\n",
    "\n",
    "    # Precompute TF-IDF vectors for all documents\n",
    "    for question_id, term_freqs in term_frequencies.items():\n",
    "        total_terms = sum(term_freqs.values())\n",
    "        tfidf_documents[question_id] = {\n",
    "            word: (freq / total_terms) * idf[word] for word, freq in term_freqs.items()\n",
    "        }\n",
    "\n",
    "    for question_id, title in question_titles.items():\n",
    "        use_embeddings[question_id] = np.array(use_model([title])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9347685-2388-4e10-b824-56abc84fb845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query_combined(query_question, answers_file, display_answer = False):\n",
    "    query_terms = query_question.lower().split()\n",
    "    query_term_frequency = defaultdict(int)\n",
    "\n",
    "    for term in query_terms:\n",
    "        if term not in stop_words:\n",
    "            query_term_frequency[term] += 1\n",
    "\n",
    "    total_query_terms = sum(query_term_frequency.values())\n",
    "    tf_query = {\n",
    "        term: (freq / total_query_terms) * idf.get(term, 0)\n",
    "        for term, freq in query_term_frequency.items()\n",
    "    }\n",
    "\n",
    "    # Get USE embedding for query\n",
    "    query_embedding = np.array(use_model([query_question])[0])\n",
    "\n",
    "    # Compute similarities\n",
    "    tfidf_similarities = {}\n",
    "    use_similarities = {}\n",
    "\n",
    "    for question_id, tfidf in tfidf_documents.items():\n",
    "        # TF-IDF similarity\n",
    "        dot_product = sum(tf_query[word] * tfidf.get(word, 0) for word in tf_query)\n",
    "        norm_query = sum(value**2 for value in tf_query.values())**0.5\n",
    "        norm_candidate = sum(value**2 for value in tfidf.values())**0.5\n",
    "        tfidf_similarities[question_id] = dot_product / (norm_query * norm_candidate + 1e-9)\n",
    "\n",
    "        # USE similarity\n",
    "        use_candidate_embed = use_embeddings[question_id]\n",
    "        use_similarities[question_id] = cosine_similarity_use(query_embedding, use_candidate_embed)\n",
    "\n",
    "    # Normalize scores\n",
    "    tfidf_similarity = normalize_scores(tfidf_similarities)\n",
    "    use_similarity = normalize_scores(use_similarities)\n",
    "\n",
    "    # Combine scores\n",
    "    alpha = 0.7 \n",
    "    combined_scores = {\n",
    "        question_id: alpha * tfidf_similarity[question_id] + (1 - alpha) * use_similarity[question_id]\n",
    "        for question_id in tfidf_similarity\n",
    "    }\n",
    "\n",
    "    top_indices = sorted(combined_scores, key=combined_scores.get, reverse=True)[:10]\n",
    "\n",
    "    print(\"Top questions and their corresponding answers:\")\n",
    "    with open(answers_file, 'r', encoding='latin-1') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        answer_dict = {row[3]: row[5] for row in reader}\n",
    "\n",
    "    for rank, question_id in enumerate(top_indices, start=1):\n",
    "        print(f\"\\nRank: {rank}\")\n",
    "        print(f\"Question ID: {question_id}\")\n",
    "        print(f\"Title: {question_titles[question_id]}\")\n",
    "        print(f\"Combined Similarity: {combined_scores[question_id]:.4f}\")\n",
    "        if question_id in answer_dict and display_answer:\n",
    "            print(f\"Answer: {answer_dict[question_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ce8ddbf-2907-46c3-9ecb-052a381237d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precompute_tfidf(questions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fe6597-9cd1-4867-8fc7-f352395b7aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "253adddc-d47b-4c17-881e-eb1245d79c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'R:\\Study\\5th Sem\\Information Retrieval\\IR PROJECT\\Saved Files\\HYBRID\\idf.pkl', 'wb') as f:\n",
    "#     pickle.dump(idf, f)\n",
    "# with open(r'R:\\Study\\5th Sem\\Information Retrieval\\IR PROJECT\\Saved Files\\HYBRID\\tfidf_documents.pkl', 'wb') as f:\n",
    "#     pickle.dump(tfidf_documents, f)\n",
    "# with open(r'R:\\Study\\5th Sem\\Information Retrieval\\IR PROJECT\\Saved Files\\HYBRID\\question_titles.pkl', 'wb') as f:\n",
    "#     pickle.dump(question_titles, f)\n",
    "# with open(r'R:\\Study\\5th Sem\\Information Retrieval\\IR PROJECT\\Saved Files\\HYBRID\\use_embeddings.pkl', 'wb') as f:\n",
    "#     pickle.dump(use_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13615f0b-c3e5-4dbd-8128-a5f545ae5e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top questions and their corresponding answers:\n",
      "\n",
      "Rank: 1\n",
      "Question ID: 23682170\n",
      "Title: using for loops\n",
      "Combined Similarity: 0.9221\n",
      "\n",
      "Rank: 2\n",
      "Question ID: 2874270\n",
      "Title: how to write this snippet in python?\n",
      "Combined Similarity: 0.9025\n",
      "\n",
      "Rank: 3\n",
      "Question ID: 9864520\n",
      "Title: perl - regex how to write this in python?\n",
      "Combined Similarity: 0.8315\n",
      "\n",
      "Rank: 4\n",
      "Question ID: 10745670\n",
      "Title: i am not sure how to use for loops to returns number of entries in table that are unique with python?\n",
      "Combined Similarity: 0.8117\n",
      "\n",
      "Rank: 5\n",
      "Question ID: 29885220\n",
      "Title: using objects in for of loops\n",
      "Combined Similarity: 0.7869\n",
      "\n",
      "Rank: 6\n",
      "Question ID: 36254600\n",
      "Title: how to loop a code in python?\n",
      "Combined Similarity: 0.7779\n",
      "\n",
      "Rank: 7\n",
      "Question ID: 18069380\n",
      "Title: write bitarray to file in python?\n",
      "Combined Similarity: 0.7758\n",
      "\n",
      "Rank: 8\n",
      "Question ID: 22591270\n",
      "Title: how to iterate in python?\n",
      "Combined Similarity: 0.7616\n",
      "\n",
      "Rank: 9\n",
      "Question ID: 12222410\n",
      "Title: arrays and for loops\n",
      "Combined Similarity: 0.7573\n",
      "\n",
      "Rank: 10\n",
      "Question ID: 13022350\n",
      "Title: for loops and arrays\n",
      "Combined Similarity: 0.7573\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query_question = \"how to write for loops in python?\"\n",
    "process_query_combined(query_question, answers_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc649838-93e3-4cfe-bb4e-2568aac2f3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top questions and their corresponding answers:\n",
      "\n",
      "Rank: 1\n",
      "Question ID: 25467300\n",
      "Title: why can't install python for android?\n",
      "Combined Similarity: 0.9469\n",
      "\n",
      "Rank: 2\n",
      "Question ID: 4329330\n",
      "Title: how to install a python package to windows?\n",
      "Combined Similarity: 0.9035\n",
      "\n",
      "Rank: 3\n",
      "Question ID: 9146320\n",
      "Title: install python mysqldb to python3 not python\n",
      "Combined Similarity: 0.8742\n",
      "\n",
      "Rank: 4\n",
      "Question ID: 31050040\n",
      "Title: install windows drivers using python\n",
      "Combined Similarity: 0.8055\n",
      "\n",
      "Rank: 5\n",
      "Question ID: 27263620\n",
      "Title: how to install anaconda python for all users?\n",
      "Combined Similarity: 0.7850\n",
      "\n",
      "Rank: 6\n",
      "Question ID: 20622860\n",
      "Title: cannot install python bottle on linux\n",
      "Combined Similarity: 0.7835\n",
      "\n",
      "Rank: 7\n",
      "Question ID: 23428840\n",
      "Title: install python packages on shared host\n",
      "Combined Similarity: 0.7717\n",
      "\n",
      "Rank: 8\n",
      "Question ID: 28293270\n",
      "Title: python api: c extension install error\n",
      "Combined Similarity: 0.7662\n",
      "\n",
      "Rank: 9\n",
      "Question ID: 29996090\n",
      "Title: getting python to wait for apt-get install\n",
      "Combined Similarity: 0.7580\n",
      "\n",
      "Rank: 10\n",
      "Question ID: 7065310\n",
      "Title: how to install pygobject with python 3 support\n",
      "Combined Similarity: 0.7533\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query_question = \"how to install python\"\n",
    "process_query_combined(query_question, answers_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "348b13c8-1c8e-4a68-b383-d143728393f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top questions and their corresponding answers:\n",
      "\n",
      "Rank: 1\n",
      "Question ID: 20989620\n",
      "Title: content search engine\n",
      "Combined Similarity: 0.9460\n",
      "\n",
      "Rank: 2\n",
      "Question ID: 6915280\n",
      "Title: php search engine for mysql\n",
      "Combined Similarity: 0.8806\n",
      "\n",
      "Rank: 3\n",
      "Question ID: 5612580\n",
      "Title: page source search engine\n",
      "Combined Similarity: 0.8806\n",
      "\n",
      "Rank: 4\n",
      "Question ID: 35133590\n",
      "Title: building sql query for search string\n",
      "Combined Similarity: 0.8401\n",
      "\n",
      "Rank: 5\n",
      "Question ID: 19970840\n",
      "Title: creating a custom search engine with asp.net\n",
      "Combined Similarity: 0.8293\n",
      "\n",
      "Rank: 6\n",
      "Question ID: 17892260\n",
      "Title: simple php/sql search engine\n",
      "Combined Similarity: 0.7624\n",
      "\n",
      "Rank: 7\n",
      "Question ID: 3594390\n",
      "Title: creating custom search webpage using google engine\n",
      "Combined Similarity: 0.7528\n",
      "\n",
      "Rank: 8\n",
      "Question ID: 17222810\n",
      "Title: complex google app engine search\n",
      "Combined Similarity: 0.7509\n",
      "\n",
      "Rank: 9\n",
      "Question ID: 33953250\n",
      "Title: search engine based on google spreadsheet\n",
      "Combined Similarity: 0.7462\n",
      "\n",
      "Rank: 10\n",
      "Question ID: 33994730\n",
      "Title: create custom search engine in google using xml file\n",
      "Combined Similarity: 0.7397\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query_question = \"Building a search engine\"\n",
    "process_query_combined(query_question, answers_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10aee651-1274-4f3c-a99a-9a33bbe6b357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top questions and their corresponding answers:\n",
      "\n",
      "Rank: 1\n",
      "Question ID: 11527720\n",
      "Title: facl commands in linux\n",
      "Combined Similarity: 0.9704\n",
      "\n",
      "Rank: 2\n",
      "Question ID: 39302440\n",
      "Title: pipe output of a binary to linux commands\n",
      "Combined Similarity: 0.9525\n",
      "\n",
      "Rank: 3\n",
      "Question ID: 6880520\n",
      "Title: sending commands from android phone to linux desktop\n",
      "Combined Similarity: 0.8944\n",
      "\n",
      "Rank: 4\n",
      "Question ID: 6311240\n",
      "Title: understanding \"intercepting\" of commands in linux\n",
      "Combined Similarity: 0.8656\n",
      "\n",
      "Rank: 5\n",
      "Question ID: 37729690\n",
      "Title: how to run all the commands before last occurrence of specific command in linux\n",
      "Combined Similarity: 0.8512\n",
      "\n",
      "Rank: 6\n",
      "Question ID: 31134730\n",
      "Title: commands in java console\n",
      "Combined Similarity: 0.7938\n",
      "\n",
      "Rank: 7\n",
      "Question ID: 11966010\n",
      "Title: loop over sql commands in a file\n",
      "Combined Similarity: 0.7746\n",
      "\n",
      "Rank: 8\n",
      "Question ID: 20115360\n",
      "Title: continuous execution of commands in linux using ganymed ssh\n",
      "Combined Similarity: 0.7507\n",
      "\n",
      "Rank: 9\n",
      "Question ID: 29518140\n",
      "Title: what is the difference between these two commands\n",
      "Combined Similarity: 0.7462\n",
      "\n",
      "Rank: 10\n",
      "Question ID: 34016860\n",
      "Title: merge commands line\n",
      "Combined Similarity: 0.7445\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query_question = \"Top linux commands\"\n",
    "process_query_combined(query_question, answers_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86aea41-acba-4089-abf5-d98eda0f75cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757b0f21-0be7-45ba-a318-de201b623029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
